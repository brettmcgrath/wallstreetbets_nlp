{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Markov NLP</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from networkx.convert_matrix import from_pandas_edgelist\n",
    "from networkx import DiGraph, Graph\n",
    "from networkx.drawing.nx_pylab import draw_networkx_nodes\n",
    "import matplotlib.pyplot as plt\n",
    "from stellargraph import StellarGraph\n",
    "from pomegranate import BayesianNetwork\n",
    "import seaborn\n",
    "import time\n",
    "import networkx\n",
    "from pomegranate.utils import plot_networkx\n",
    "import operator\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create start timestamp to calculate notebook runtime at bottom</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-11 22:16:50.033740\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markov_chain_perc = markov_chain(brand_data, 'rm_dup_brand', 3, True)\n",
    "# markov_chain_num = markov_chain(brand_data, 'rm_dup_brand', 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../finance/crypto/reddit/wallstreetbets_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699539, 10)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>post</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>is_submitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parker2020</td>\n",
       "      <td>Hate to see it</td>\n",
       "      <td>1617465910</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/mhs01t/unpinned_dai...</td>\n",
       "      <td>t1_gt97zak</td>\n",
       "      <td>gt98ckt</td>\n",
       "      <td>t3_mhs01t</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FannyPackPhantom</td>\n",
       "      <td>It’s 100% better than any of the girls or high...</td>\n",
       "      <td>1617465909</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/mhs01t/unpinned_dai...</td>\n",
       "      <td>t1_gt97lzp</td>\n",
       "      <td>gt98ci7</td>\n",
       "      <td>t3_mhs01t</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8an5</td>\n",
       "      <td>So many triangles, it must be a message from t...</td>\n",
       "      <td>1617465899</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/mj5rgl/gme_will_we_...</td>\n",
       "      <td>t3_mj5rgl</td>\n",
       "      <td>gt98btc</td>\n",
       "      <td>t3_mj5rgl</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AllRealTruth</td>\n",
       "      <td>Much better than buying a stock at $2 .. selli...</td>\n",
       "      <td>1617465892</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/mj5rgl/gme_will_we_...</td>\n",
       "      <td>t1_gt8phb6</td>\n",
       "      <td>gt98ban</td>\n",
       "      <td>t3_mj5rgl</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>derficker69</td>\n",
       "      <td>Are you aware that you are supporting [this bu...</td>\n",
       "      <td>1617465892</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/m7bbb9/added_more_p...</td>\n",
       "      <td>t1_gra9hei</td>\n",
       "      <td>gt98bae</td>\n",
       "      <td>t3_m7bbb9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                               post  \\\n",
       "0        parker2020                                     Hate to see it   \n",
       "1  FannyPackPhantom  It’s 100% better than any of the girls or high...   \n",
       "2              8an5  So many triangles, it must be a message from t...   \n",
       "3      AllRealTruth  Much better than buying a stock at $2 .. selli...   \n",
       "4       derficker69  Are you aware that you are supporting [this bu...   \n",
       "\n",
       "   created_utc       subreddit  score  \\\n",
       "0   1617465910  wallstreetbets      1   \n",
       "1   1617465909  wallstreetbets      1   \n",
       "2   1617465899  wallstreetbets      1   \n",
       "3   1617465892  wallstreetbets      1   \n",
       "4   1617465892  wallstreetbets      1   \n",
       "\n",
       "                                           permalink   parent_id       id  \\\n",
       "0  /r/wallstreetbets/comments/mhs01t/unpinned_dai...  t1_gt97zak  gt98ckt   \n",
       "1  /r/wallstreetbets/comments/mhs01t/unpinned_dai...  t1_gt97lzp  gt98ci7   \n",
       "2  /r/wallstreetbets/comments/mj5rgl/gme_will_we_...   t3_mj5rgl  gt98btc   \n",
       "3  /r/wallstreetbets/comments/mj5rgl/gme_will_we_...  t1_gt8phb6  gt98ban   \n",
       "4  /r/wallstreetbets/comments/m7bbb9/added_more_p...  t1_gra9hei  gt98bae   \n",
       "\n",
       "     link_id  is_submitter  \n",
       "0  t3_mhs01t         False  \n",
       "1  t3_mhs01t         False  \n",
       "2  t3_mj5rgl         False  \n",
       "3  t3_mj5rgl         False  \n",
       "4  t3_m7bbb9         False  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chuck Norris trades on Saturday, Sunday and on all statutory holidays.'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[45]['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    text = str(text).lower() \\\n",
    "    .replace(\"it's\", \"it is\") \\\n",
    "    .replace(\"we'll\", \"we will\") \\\n",
    "    .replace(\"she'll\", \"she will\") \\\n",
    "    .replace(\"he'll\", \"he will\") \\\n",
    "    .replace(\"hasn't\", \"has not\") \\\n",
    "    .replace(\"isn't\", \"is not\") \\\n",
    "    .replace(\"won't\", \"will not\") \\\n",
    "    .replace(\"shouldn't\", \"should not\") \\\n",
    "    .replace(\",\", \"\")\n",
    "    \n",
    "    text = re.sub('oo+', 'oo', text)\n",
    "    text = re.sub('aa+', 'a', text)\n",
    "    text = re.sub('ee+', 'ee', text)\n",
    "    text = re.sub('ii+', 'i', text)\n",
    "    text = re.sub('uu+', 'u', text)\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    \n",
    "    rest_of_alphabet = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n",
    "    for i in rest_of_alphabet:\n",
    "        text = re.sub(f'{i}{i}{i}+', f'{i}',text)\n",
    "    \n",
    "    return text.split(' ')\n",
    "\n",
    "df['cleaned_post'] = df['post'].apply(lambda x: clean_and_tokenize(x))\n",
    "df['cleaned_post_length'] = df['cleaned_post'].apply(lambda x: len(x))\n",
    "df = df[df['cleaned_post_length'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tsm',\n",
       " 'is',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'esports',\n",
       " 'team',\n",
       " 'there',\n",
       " 'for',\n",
       " 'ima',\n",
       " 'go',\n",
       " 'for',\n",
       " 'it']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[45]['cleaned_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579047, 12)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10342707"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_post_length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_vocab(df, sequence_column):\n",
    "#     vocab = []\n",
    "#     for i in range(len(df)):\n",
    "#         if i % 50000 == 0:\n",
    "#             print(i)\n",
    "#         for j in df.iloc[i][sequence_column]:\n",
    "#             if j in vocab:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 vocab.append(j)\n",
    "#     print(f'{len(vocab)} word vocabulary created')\n",
    "#     return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(df, sequence_column):\n",
    "    all_words = []\n",
    "    for i in range(len(df)):\n",
    "        if i % 50000 == 0:\n",
    "            print(i)\n",
    "        for j in df.iloc[i][sequence_column]:\n",
    "                all_words.append(j)\n",
    "    c = dict(collections.Counter(all_words))\n",
    "    return [i for i in c.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(df, 'cleaned_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336740"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(df, vocab, sequence_column, k=3):\n",
    "    print(datetime.now())\n",
    "    markov_dict = {}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i % 50000 == 0:\n",
    "            print(i)\n",
    "        listy = df.iloc[i][sequence_column]\n",
    "\n",
    "        for l, m in enumerate(listy):\n",
    "            if l < len(listy)-(k+1):\n",
    "                sequence = (' '.join(listy[l:l+k]))\n",
    "#                 print(sequence)\n",
    "                if sequence in markov_dict.keys():\n",
    "#                     print('a')\n",
    "                    try:\n",
    "                        markov_dict[sequence][listy[l+k]] +=1\n",
    "                    except KeyError:\n",
    "                        markov_dict[sequence][listy[l+k]] = 1\n",
    "                else: \n",
    "#                     print('b')\n",
    "                    markov_dict[sequence] = {listy[l+k]:1}\n",
    "#                     markov_dict[sequence][listy[l+k+1]] += 1\n",
    "           \n",
    "#     if percent==True:                \n",
    "#         for i in markov_dict.keys():\n",
    "#             total = sum(markov_dict[i].values())\n",
    "#             for j in vocab:\n",
    "#                 new_value = (markov_dict[i][j])/total\n",
    "#                 markov_dict[i][j] = new_value\n",
    "                \n",
    "    print(datetime.now())            \n",
    "    return markov_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-11 22:18:07.749598\n",
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "2021-07-11 22:19:06.133878\n"
     ]
    }
   ],
   "source": [
    "wsb = markov_chain(df, vocab, 'cleaned_post', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(sequence, iterations, k):\n",
    "    \"\"\"sequence = str\n",
    "    \"\"\"\n",
    "    listy = []\n",
    "    text = sequence.split(' ')\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        words = \" \".join(text[-k:])\n",
    "        markov = wsb[words]\n",
    "        total = sum(wsb[sequence].values())\n",
    "        nexty = max(markov.items(), key=operator.itemgetter(1))[0]\n",
    "        num = max(markov.items(), key=operator.itemgetter(1))[1]\n",
    "        perc = (max(markov.items(), key=operator.itemgetter(1))[1])/total\n",
    "        listy.append([nexty, perc, num])\n",
    "        text.append(nexty)\n",
    "    return listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['do', 0.8148148148148148, 22],\n",
       " ['with', 0.4444444444444444, 12],\n",
       " ['the', 0.1111111111111111, 3],\n",
       " ['$1.4m', 0.037037037037037035, 1],\n",
       " ['if', 0.037037037037037035, 1],\n",
       " ['it', 0.037037037037037035, 1],\n",
       " ['is', 0.037037037037037035, 1],\n",
       " ['enough', 0.037037037037037035, 1],\n",
       " ['to', 0.037037037037037035, 1],\n",
       " ['retire', 0.037037037037037035, 1]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(\"what are you going to\", 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do': 22, 'call': 1, 'buy?': 1, 'sell?': 1, 'grow': 1, 'do?': 1}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb[\"what are you going to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "print(end)\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
